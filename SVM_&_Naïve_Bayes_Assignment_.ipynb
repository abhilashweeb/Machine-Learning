{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment Code: DA-AG-013"
      ],
      "metadata": {
        "id": "qHg7Q4Zj0CEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Theoritical & Practical Question"
      ],
      "metadata": {
        "id": "m0JDBd6c0Kgb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is a Support Vector Machine (SVM), and how does it work?\n",
        "* A Support Vector Machine (SVM) is a supervised learning algorithm used for both classification and regression. It works by finding the optimal hyperplane that separates data points of different classes with the maximum margin. The closest points to this boundary, called support vectors, play a key role in defining it. By maximizing the margin, SVM improves generalization and is especially effective in high-dimensional spaces.\n",
        "\n",
        "Question 2: Explain the difference between Hard Margin and Soft Margin SVM.\n",
        "* In a Hard Margin SVM, the goal is to find a hyperplane that separates the classes perfectly, with no misclassifications. This works only when the data is linearly separable and is highly sensitive to noise or outliers.\n",
        "* In a Soft Margin SVM, some misclassifications are allowed by introducing a penalty term. This trade-off between maximizing the margin and minimizing errors makes it more robust and suitable for real-world, noisy datasets.\n",
        "\n",
        "Question 3: What is the Kernel Trick in SVM? Give one example of a kernel and\n",
        "explain its use case.\n",
        "* The Kernel Trick in SVM is a method that enables the algorithm to separate data that is not linearly separable. It works by implicitly mapping the data into a higher-dimensional space using a kernel function, without having to perform the actual transformation. This makes computations efficient while allowing SVM to model complex decision boundaries.\n",
        "* For example, the Radial Basis Function (RBF) kernel projects data into an infinite-dimensional space, making it effective for problems with non-linear relationships. It is commonly used in applications like image recognition and text classification.\n",
        "\n",
        "Question 4: What is a Naïve Bayes Classifier, and why is it called “naïve”?\n",
        "* A Naïve Bayes Classifier is a simple machine learning algorithm used for classification. It is based on Bayes’ Theorem, which helps us calculate the probability of something happening given some evidence. The classifier predicts the class that has the highest probability for the given features.\n",
        "* It is called “naïve” because it assumes that all features are independent of each other, which usually isn’t true in real life. Even with this simple assumption, it works very well in practice — for example, in spam email detection or text classification.\n",
        "\n",
        "Question 5: Describe the Gaussian, Multinomial, and Bernoulli Naïve Bayes variants. When would you use each one?\n",
        "* The Naïve Bayes Classifier comes in different types depending on the kind of data we have:\n",
        "     * Gaussian Naïve Bayes: Used when the features are numbers that follow a normal distribution (like height, weight, or exam scores).\n",
        "     * Multinomial Naïve Bayes: Used when features are counts, such as how many times a word appears in a document. This is very common in text classification.\n",
        "     * Bernoulli Naïve Bayes: Used when features are just yes/no or 0/1 values, like whether a word is present in a document or not.\n",
        "* In short:\n",
        "      * Gaussian → numbers/continuous data\n",
        "      * Multinomial → counts (word frequency)\n",
        "      * Bernoulli → yes/no features\n",
        "\n",
        "\n",
        "Dataset Info:\n",
        "* You can use any suitable datasets like Iris, Breast Cancer, or Wine from\n",
        "sklearn.datasets or a CSV file you have.\n",
        "\n",
        "Question 6: Write a Python program to:\n",
        "* Load the Iris dataset\n",
        "* Train an SVM Classifier with a linear kernel\n",
        "* Print the model's accuracy and support vectors.\n",
        "* (Include your Python code and output in the code box below.)\n"
      ],
      "metadata": {
        "id": "F7hzcPkl0RqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "df = pd.DataFrame(data = iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "model = SVC(kernel='linear')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Support Vectors:\", model.support_vectors_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2telbrv3dzf",
        "outputId": "7ea3d589-f4f4-4360-dcbb-fc176a8d4e89"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Support Vectors: [[5.1 3.3 1.7 0.5]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.  3.  4.8 1.8]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [6.3 2.8 5.1 1.5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to:\n",
        "*  Load the Breast Cancer dataset\n",
        "* Train a Gaussian Naïve Bayes model\n",
        "* Print its classification report including precision, recall, and F1-score.\n",
        "* (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "HWd0BGI_4BqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "df = pd.DataFrame(data = cancer.data, columns=cancer.feature_names)\n",
        "df['target'] = cancer.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=1\n",
        ")\n",
        "\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=cancer.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF5xQHNJ4wW_",
        "outputId": "7d0b8ebc-97f2-4b45-87c8-2298f9f22877"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.94      0.92      0.93        63\n",
            "      benign       0.95      0.96      0.96       108\n",
            "\n",
            "    accuracy                           0.95       171\n",
            "   macro avg       0.94      0.94      0.94       171\n",
            "weighted avg       0.95      0.95      0.95       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to:\n",
        "* Train an SVM Classifier on the Wine dataset using GridSearchCV to find the best C and gamma.\n",
        "*  Print the best hyperparameters and accuracy.\n",
        "* (Include your Python code and output in the code box below.)\n"
      ],
      "metadata": {
        "id": "27nm0D2q5MDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Wine dataset\n",
        "wine = datasets.load_wine()\n",
        "X, y = wine.data, wine.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define SVM and parameter grid\n",
        "param_grid = {'C': [0.1, 1, 10, 100],\n",
        "              'gamma': [0.001, 0.01, 0.1, 1],\n",
        "              'kernel': ['rbf']}\n",
        "\n",
        "# Grid search\n",
        "grid = GridSearchCV(SVC(), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Best model results\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "print(\"Best Hyperparameters:\", grid.best_params_)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy5vs8Yn6GgA",
        "outputId": "ea20a162-7944-4764-aa1e-9c3ea06a9646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Test Accuracy: 0.8333333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to:\n",
        "* Train a Naïve Bayes Classifier on a synthetic text dataset (e.g. using\n",
        "sklearn.datasets.fetch_20newsgroups).\n",
        "* Print the model's ROC-AUC score for its predictions.\n",
        "* (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "BczMsXxa6gDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import needed libraries\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# 1. Load the 20 Newsgroups text dataset\n",
        "X, y = fetch_20newsgroups(subset='all',\n",
        "                          remove=('headers','footers','quotes'),\n",
        "                          return_X_y=True)\n",
        "\n",
        "# 2. Convert text into numerical features using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X = vectorizer.fit_transform(X)\n",
        "\n",
        "# 3. Split dataset into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Train a Naïve Bayes Classifier\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Evaluate using ROC-AUC score\n",
        "y_prob = model.predict_proba(X_test)\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob, multi_class='ovr'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8hAfBQr6vin",
        "outputId": "8dccd153-2c12-4f8a-8679-026e878046d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9613427017995614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you’re working as a data scientist for a company that handles email communications.\n",
        "Your task is to automatically classify emails as Spam or Not Spam. The emails may contain:\n",
        "* Text with diverse vocabulary\n",
        "* Potential class imbalance (far more legitimate emails than spam)\\\n",
        "* Some incomplete or missing data\n",
        "Explain the approach you would take to:\n",
        "* Preprocess the data (e.g. text vectorization, handling missing data)\n",
        "* Choose and justify an appropriate model (SVM vs. Naïve Bayes)\n",
        "* Address class imbalance\n",
        "* Evaluate the performance of your solution with suitable metrics\n",
        "And explain the business impact of your solution.\n",
        "* (Include your Python code and output in the code box below.)\n",
        "\n",
        "Answer-\n",
        "Approach Explanation:\n",
        "1. Preprocessing the Data\n",
        "* Handle missing values: Replace missing emails with empty strings.\n",
        "* Text Vectorization: Convert email text into numerical form using TF-IDF (Term Frequency – Inverse Document Frequency) so that ML models can understand it.\n",
        "* Lowercasing, removing stopwords, punctuation, etc.\n",
        "\n",
        "2. Model Choice\n",
        "* We’ll use Naïve Bayes because:\n",
        "  * It works great for text problems.\n",
        "  * It’s simple and fast.\n",
        "\n",
        "3. Balance the Data\n",
        "* Usually, there are more “Not Spam” emails than “Spam”.\n",
        "* We use SMOTE to create extra spam samples, so the model learns fairly.\n",
        "\n",
        "4. Check Performance\n",
        "* Use Precision, Recall, and F1-score (important for spam detection).\n",
        "* Recall is most important → we don’t want to miss spam.\n",
        "\n",
        "5. Business Value\n",
        "* Blocks spam → saves time and protects users from scams.\n",
        "* Keeps important emails safe → avoids false alarms."
      ],
      "metadata": {
        "id": "E6jwUevyALwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Example dataset\n",
        "data = {\n",
        "    \"text\": [\n",
        "        \"Congratulations, you won a lottery prize!\",\n",
        "        \"Meeting tomorrow at 10am\",\n",
        "        \"Get cheap pills now!!!\",\n",
        "        \"Project deadline next week\",\n",
        "        \"You have been selected for prize money!!!\",\n",
        "        \"Can we reschedule the call?\"\n",
        "    ],\n",
        "    \"label\": [\"spam\", \"ham\", \"spam\", \"ham\", \"spam\", \"ham\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Handle missing values\n",
        "df[\"text\"] = df[\"text\"].fillna(\"\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.3, random_state=42)\n",
        "\n",
        "# Text vectorization\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Fix class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train_vec, y_train)\n",
        "\n",
        "# Train model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Prediction\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt_PhvA5CsEI",
        "outputId": "c1573849-a5ae-4a42-e490-35e8f67f6cbf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         ham       1.00      1.00      1.00         1\n",
            "        spam       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Db14TbqQCtJC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}