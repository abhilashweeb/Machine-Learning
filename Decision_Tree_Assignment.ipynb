{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Theory and Practical Questions"
      ],
      "metadata": {
        "id": "8rVsidLLDzZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is a Decision Tree, and how does it work in the context of\n",
        "classification?\n",
        "* A Decision Tree is a supervised learning algorithm used for both classification and regression tasks. In classification, it works by recursively splitting the dataset into smaller subsets based on feature values. Each split is made using conditions that maximize the separation of classes, and this process continues until we reach leaf nodes, which represent the final class labels. You can think of it as a sequence of yes/no questions that guide us step by step toward the correct category.\n",
        "\n",
        "Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?\n",
        "* Gini Impurity and Entropy are metrics used to evaluate how mixed or impure the classes are in a dataset. Gini Impurity measures the probability of incorrectly classifying a randomly chosen element, while Entropy quantifies the level of randomness or disorder in the data. In building a Decision Tree, we select splits that achieve the greatest reduction in impurity, and these measures guide us in choosing the most informative feature to split on.\n",
        "Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.\n",
        "* Pre-pruning means restricting the growth of a Decision Tree early by setting limits such as maximum depth, minimum samples per split, or minimum leaf size. This helps prevent overfitting and reduces computation time. Post-pruning, on the other hand, allows the tree to grow fully and then prunes back unnecessary branches to simplify the model. While pre-pruning is faster and more efficient, post-pruning often produces a more accurate and generalized model.\n",
        "\n",
        "Question 4: What is Information Gain in Decision Trees, and why is it important for choosing the best split?\n",
        "* Information Gain measures the reduction in uncertainty or impurity when the data is split using a particular feature. It is calculated by comparing the entropy before the split with the weighted entropy after the split. A higher Information Gain indicates that the feature is more effective at separating the classes. This makes it an important criterion for selecting the most informative features, resulting in a more accurate and efficient Decision Tree.\n",
        "\n",
        "Question 5: What are some common real-world applications of Decision Trees, and\n",
        "what are their main advantages and limitations?\n",
        "* Decision Trees are widely applied in fields such as medical diagnosis, credit risk assessment, fraud detection, and customer segmentation. Their key advantage lies in being easy to understand, interpret, and visualize. However, they are prone to overfitting and may struggle with very large or noisy datasets unless techniques like pruning or ensemble methods are applied.\n",
        "\n",
        "Dataset Info:\n",
        "* Iris Dataset for classification tasks (sklearn.datasets.load_iris() or provided CSV).\n",
        "* Boston Housing Dataset for regression tasks (sklearn.datasets.load_boston() or provided CSV).\n",
        "\n",
        "Question 6: Write a Python program to:\n",
        "* Load the Iris Dataset\n",
        "* Train a Decision Tree Classifier using the Gini criterion\n",
        "* Print the modelâ€™s accuracy and feature importances\n",
        "* (Include your Python code and output in the code box below.)\n",
        "\n"
      ],
      "metadata": {
        "id": "XUJfQyOZD9JQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer:\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "\n",
        "classifier = DecisionTreeClassifier(criterion='gini')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(\"Feature Importances:\", classifier.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ogZ129gtqp7",
        "outputId": "d48fdd4b-6134-4b31-e30d-cf6a9679ad9e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9555555555555556\n",
            "Feature Importances: [0.02146947 0.02146947 0.57196476 0.38509631]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to:\n",
        "* Load the Iris Dataset\n",
        "* Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to fully-grown tree.\n",
        "* (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "v89RDHSst8bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer:\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "classifier_limited = DecisionTreeClassifier(max_depth=3)\n",
        "classifier_limited.fit(X_train, y_train)\n",
        "y_pred_limited = classifier_limited.predict(X_test)\n",
        "acc_limited = accuracy_score(y_test, y_pred_limited)\n",
        "\n",
        "classifier_full = DecisionTreeClassifier()\n",
        "classifier_full.fit(X_train, y_train)\n",
        "y_pred_full = classifier_full.predict(X_test)\n",
        "acc_full = accuracy_score(y_test, y_pred_full)\n",
        "\n",
        "print(f\"Accuracy with max_depth=3: {acc_limited}\")\n",
        "print(f\"Accuracy with fully grown tree: {acc_full}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMBvnW0euU0G",
        "outputId": "69b8eece-a672-44f2-b72d-4fe4d1a4a10f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with max_depth=3: 0.9555555555555556\n",
            "Accuracy with fully grown tree: 0.9555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to:\n",
        "* Load the California Housing dataset from sklearn\\\n",
        "* Train a Decision Tree Regressor\n",
        "* Print the Mean Squared Error (MSE) and feature importances\n",
        "* (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "ULtd9zuKubvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer:\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "df['target'] = housing.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "regressor = DecisionTreeRegressor()\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(\"Feature Importances:\", regressor.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bavPE2gvbCI",
        "outputId": "00ba5a5a-753c-4a55-c57a-3c357d533ff4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.49275203360544245\n",
            "Feature Importances: [0.50916108 0.05132538 0.02996523 0.02690529 0.02699413 0.14046386\n",
            " 0.10803194 0.10715309]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to:\n",
        "* Load the Iris Dataset\n",
        "* Tune the Decision Treeâ€™s max_depth and min_samples_split using\n",
        "GridSearchCV\n",
        "* Print the best parameters and the resulting model accuracy\n",
        "* (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "zxqgGV5-vuxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer:\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, None],\n",
        "    'min_samples_split': [2, 3, 4, 5]\n",
        "}\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with Best Parameters: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpVw5-nFwAn5",
        "outputId": "7ad6aba6-e104-4a62-f0f7-a3b647060b74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 3, 'min_samples_split': 2}\n",
            "Model Accuracy with Best Parameters: 0.9555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine youâ€™re working as a data scientist for a healthcare company that wants to predict whether a patient has a certain disease. You have a large dataset with mixed data types and some missing values.\n",
        "Explain the step-by-step process you would follow to:\n",
        "* Handle the missing values\n",
        "* Encode the categorical features\n",
        "* Train a Decision Tree model\n",
        "* Tune its hyperparameters\n",
        "* Evaluate its performance\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting.\n",
        "\n",
        "Answer-\n",
        "*  Handle Missing Values: For numerical features, we can use mean or median imputation, and for categorical features, we can use the most frequent category to fill missing values.\n",
        "* Encode Categorical Features: Apply One-Hot Encoding or Label Encoding so that the Decision Tree can understand categorical data.\n",
        "* Train the Decision Tree: Split the dataset into training and testing sets, then train a Decision Tree model on the training data.\n",
        "* Tune Hyperparameters: Use GridSearchCV or RandomizedSearchCV to find the best values for parameters like max_depth, min_samples_split, and criterion.\n",
        "* Evaluate the Model: Check performance using metrics like accuracy, precision, recall, F1-score, and ROC-AUC to ensure reliability.\n",
        "* This model can help healthcare professionals predict diseases early, identify high-risk patients, and support better decision-making. It reduces manual workload, improves efficiency, and ultimately leads to better patient outcomes and cost savings for the company."
      ],
      "metadata": {
        "id": "vyat-SP8wZ6U"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Y3ao5prw-qN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}